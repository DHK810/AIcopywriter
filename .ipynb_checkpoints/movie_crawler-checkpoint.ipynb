{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-50 of 90,647 titles.\n",
      "| Next »\n",
      "\n",
      "50\n",
      "\n",
      "1-50 of 13,156 titles.\n",
      "| Next »\n",
      "\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "#전역 변수\n",
    "url = 'https://www.imdb.com/search/title/?genres={}&title_type=movie&start={}'\n",
    "script_list = []   #다른 함수에서도 써야하기 때문에 전역변수로 선언\n",
    "episode_list = []\n",
    "genres = ['comedy', 'sci-fi', 'horror', 'romance', 'action', 'thriller',\n",
    "         'drama', 'mystery', 'crime', 'animation', 'adventure', 'fantasy',\n",
    "         'comedy-romance', 'action-comedy', 'superhero']\n",
    "\n",
    "#대본 크롤링\n",
    "def movie_crawling():\n",
    "    \n",
    "    for genre in genres[:2]:\n",
    "        g_url = url.format(genre, 1)\n",
    "        resp = requests.get(g_url)\n",
    "        soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "        find_moviecount = soup.find('div', class_ = 'desc').text\n",
    "        print(find_moviecount)\n",
    "        find_frame = soup.find('div', class_ = 'lister-list')\n",
    "        find_list = find_frame.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "        \n",
    "        \n",
    "        print(len(find_list))\n",
    "\n",
    "movie_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/search/title/?genres=comedy&title_type=movie&start=1',\n",
       " 'https://www.imdb.com/search/title/?genres=sci-fi&title_type=movie&start=1']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genre_url():\n",
    "    url_list = []\n",
    "    for genre in genres[:2]:\n",
    "        g_url = url.format(genre, 1)\n",
    "        url_list.append(g_url)\n",
    "    return url_list\n",
    "genres_url = genre_url()\n",
    "genres_url\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_everypage_url(genres_url):\n",
    "    for g_url in genres_url:\n",
    "        resp = requests.get(g_url)\n",
    "        soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "        find_moviecount = soup.find('div', class_ = 'desc').text.split()[2]\n",
    "        find_moviecount = int(find_moviecount.replace(',', ''))\n",
    "        print(find_moviecount)\n",
    "\n",
    "        #넥스트 페이지 50개씩 넘어감\n",
    "        try:\n",
    "            for page_no in range(1, find_moviecount, 50):\n",
    "                print(page_no)\n",
    "                next_g_url = g_url.format(genre, page_no)\n",
    "                resp = requests.get(next_g_url)\n",
    "                soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "                find_frame = soup.find('div', class_ = 'lister-list')\n",
    "                find_list = find_frame.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "                movie_url = []\n",
    "                for list_ in find_list:\n",
    "                    a_tag = list_.find('a').attrs['href']\n",
    "                    url = 'https://www.imdb.com' + a_tag\n",
    "                    movie_url.append(url)\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90647\n",
      "1\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'find_list' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-cc0b4180f2c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenre_everypage_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenres_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-da8c9c487131>\u001b[0m in \u001b[0;36mgenre_everypage_url\u001b[1;34m(genres_url)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'find_list' referenced before assignment"
     ]
    }
   ],
   "source": [
    "genre_everypage_url(genres_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/title/tt2935510/?ref_=adv_li_tt'\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-20a0f44b8a32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovie_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'movie_url' is not defined"
     ]
    }
   ],
   "source": [
    "movie_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    resp = requests.get(url, params = params)\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    \n",
    "    find_frame = soup.find('div', class_ = 'main-content-left')           #가장 바깥 프레임 설정\n",
    "    find_seasons = find_frame.find_all('div', class_ = 'season-episodes') #모든 시즌 가져오기\n",
    "                                                                          #find_seasons[0] = season1\n",
    "\n",
    "    url_list = []                                     #각 에피소드들의 주소를 담을 리스트\n",
    "    url_base = 'https://www.springfieldspringfield.co.uk/'  \n",
    "    for season in find_seasons:                            \n",
    "        #에피소드 태그 추출               \n",
    "        a_tags = season.find_all('a')    \n",
    "                                      \n",
    "        for a in a_tags:\n",
    "            url_tag = a.attrs['href']                #에피소드 별 주소 추출            \n",
    "            url_tag = url_base + url_tag             # 대본으로 가는 url 합치기        \n",
    "            url_list.append(url_tag)                 #에피소드 대본 url a_tag_list에 넣기            \n",
    "\n",
    "    print(url_list)\n",
    "\n",
    "    #https://www.springfieldspringfield.co.uk/view_episode_scripts.php?tv-show=breaking-bad&episode=s01e01  's01e01' 만 빼오기    \n",
    "    for i in url_list:    \n",
    "        episode = i[-5:] \n",
    "        episode_list.append(episode)\n",
    "    print(episode_list)\n",
    "    \n",
    "    #에피소드별 url에 접속 후 대본 가져오기\n",
    "\n",
    "    count = 0\n",
    "    for script_url in url_list:           #seasons_list 각 인덱스에 있는 url에 접속\n",
    "        script_resp = requests.get(script_url)\n",
    "        script_soup = BeautifulSoup(script_resp.content, 'html.parser')\n",
    "        script_list.append(script_soup.find('div', class_ = 'scrolling-script-container').text)  #대본 페이지 본문 긁어 오기\n",
    "        \n",
    "        #제한 설정: 10개 에피소드 긁어오기\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break\n",
    "#script crwaling end \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
